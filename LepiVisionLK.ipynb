{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMskGCL7zTFRMuOl2SAB/Lo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhanura/lepi_vision_lk/blob/main/LepiVisionLK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Google Drive & Install Libraries"
      ],
      "metadata": {
        "id": "dNN5G7jaGgiZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vpEw-ayOGGpI",
        "outputId": "f3fd9072-b56f-456a-e1f7-743b219169cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Install the library for MobileNetV4\n",
        "!pip install timm pandas scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the Data"
      ],
      "metadata": {
        "id": "1RqKTwrKHoem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Lepi Vision LK/butterfly_images.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Unzipping data...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Unzip complete!\")\n",
        "else:\n",
        "    print(\"Data already unzipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2aruuc8HrmJ",
        "outputId": "db39bf01-097d-44f0-cf60-900eae0e7024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping data...\n",
            "Unzip complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Training Script"
      ],
      "metadata": {
        "id": "yAWojKvbImeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Check the left sidebar folder icon in Colab to confirm this path!\n",
        "BASE_DIR = '/content/dataset'\n",
        "DATA_CSV = os.path.join(BASE_DIR, 'butterfly_images.csv')\n",
        "IMAGE_FOLDER = os.path.join(BASE_DIR, 'butterfly_images')\n",
        "\n",
        "MODEL_NAME = 'mobilenetv4_conv_small.e2400_r224_in1k'\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15 # You can increase this since GPU is fast\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Setup GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# --- DATASET CLASS ---\n",
        "class ButterflyDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img_name_base = row.iloc[0]\n",
        "        label = row.iloc[-1] # Ensure we take the encoded label\n",
        "\n",
        "        image = None\n",
        "        extensions = ['.jpg', '.jpeg', '.png'] # Try common image extensions\n",
        "        for ext in extensions:\n",
        "            img_path = os.path.join(self.root_dir, img_name_base + ext)\n",
        "            try:\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                break # Image found and opened, break from extension loop\n",
        "            except FileNotFoundError:\n",
        "                continue # Try next extension\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "                image = None # Mark as not loaded due to other error\n",
        "                break # Stop trying other extensions for this image if another error occurs\n",
        "\n",
        "        if image is None:\n",
        "            # If no image was successfully loaded after trying all extensions\n",
        "            print(f\"Warning: Image {img_name_base} not found with extensions {extensions}. Skipping.\")\n",
        "            next_idx = (idx + 1) % len(self.dataframe)\n",
        "            if next_idx == idx: # Avoid infinite loop if only one image or all are bad\n",
        "                raise FileNotFoundError(f\"No valid image found after trying to load {img_name_base}\")\n",
        "            return self.__getitem__(next_idx)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# --- PREPARE DATA ---\n",
        "if os.path.exists(DATA_CSV):\n",
        "    df = pd.read_csv(DATA_CSV)\n",
        "\n",
        "    # Encoder\n",
        "    le = LabelEncoder()\n",
        "    # Assuming the names are in the 2nd column (index 1)\n",
        "    df['encoded_label'] = le.fit_transform(df.iloc[:, 1])\n",
        "    NUM_CLASSES = len(le.classes_)\n",
        "    print(f\"Classes found: {le.classes_}\")\n",
        "\n",
        "    # Split\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['encoded_label'])\n",
        "\n",
        "    # Transforms\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(ButterflyDataset(train_df, IMAGE_FOLDER, train_transforms), batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(ButterflyDataset(val_df, IMAGE_FOLDER, val_transforms), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # --- MODEL SETUP ---\n",
        "    model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # --- TRAINING LOOP ---\n",
        "    print(\"Starting Training...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {running_loss/len(train_loader):.4f} | Acc: {100 * correct / total:.2f}%\")\n",
        "\n",
        "    # Save to Colab workspace\n",
        "    torch.save(model.state_dict(), \"butterfly_model.pth\")\n",
        "    print(\"Training Complete. Model saved.\")\n",
        "else:\n",
        "    print(f\"Error: Could not find {DATA_CSV}. Check your folder structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alsYtrNpIn8S",
        "outputId": "e8cf231d-209b-42d1-f3d6-0a6f9a7e8625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cuda\n",
            "Classes found: ['b001' 'b002' 'b003' 'b004' 'b005' 'b006' 'b007']\n",
            "Starting Training...\n",
            "Epoch 1/15 | Loss: 4.8913 | Acc: 20.69%\n",
            "Epoch 2/15 | Loss: 2.2546 | Acc: 58.62%\n",
            "Epoch 3/15 | Loss: 2.2006 | Acc: 63.22%\n",
            "Epoch 4/15 | Loss: 2.8022 | Acc: 58.62%\n",
            "Epoch 5/15 | Loss: 1.8693 | Acc: 62.07%\n",
            "Epoch 6/15 | Loss: 1.3564 | Acc: 64.37%\n",
            "Epoch 7/15 | Loss: 1.2154 | Acc: 68.97%\n",
            "Epoch 8/15 | Loss: 0.8703 | Acc: 71.26%\n",
            "Epoch 9/15 | Loss: 1.2439 | Acc: 71.26%\n",
            "Epoch 10/15 | Loss: 0.9332 | Acc: 75.86%\n",
            "Epoch 11/15 | Loss: 0.5098 | Acc: 85.06%\n",
            "Epoch 12/15 | Loss: 0.8136 | Acc: 83.91%\n",
            "Epoch 13/15 | Loss: 0.5994 | Acc: 88.51%\n",
            "Epoch 14/15 | Loss: 0.5835 | Acc: 83.91%\n",
            "Epoch 15/15 | Loss: 0.4364 | Acc: 89.66%\n",
            "Training Complete. Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Model back to Google Drive"
      ],
      "metadata": {
        "id": "8Iqu0DD6OKuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Copy the trained model from Colab to your Google Drive folder\n",
        "shutil.copy(\"butterfly_model.pth\", \"/content/drive/MyDrive/Lepi Vision LK/lepi_vision_lk.pth\")\n",
        "print(\"Model successfully saved to Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNWyOZZTOXSE",
        "outputId": "4b7fe204-dfd4-4412-8fee-3c82ac0fc15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved to Google Drive!\n"
          ]
        }
      ]
    }
  ]
}